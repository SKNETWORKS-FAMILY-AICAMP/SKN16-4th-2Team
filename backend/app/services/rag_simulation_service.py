"""
RAG ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì„œë¹„ìŠ¤
ì œê³µëœ ë°ì´í„°ë¥¼ í™œìš©í•œ STT/LLM/TTS ê¸°ë°˜ ìŒì„± ì‹œë®¬ë ˆì´ì…˜
"""
import json
import os
import tempfile
import base64
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime
from sqlmodel import Session, select
import openai
from pathlib import Path

from app.models.user import User
from app.services.promptOrchestrator import (
    compose_llm_messages,
    parse_llm_response,
    get_situation_defaults
)
from app.services.banking_normalizer import normalize_text, expand_search_query
from app.services.persona_voice import get_voice_params, build_ssml


class RAGSimulationService:
    """RAG ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì„œë¹„ìŠ¤"""
    
    def __init__(self, session: Session):
        self.session = session
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            try:
                self.openai_client = openai.OpenAI(api_key=api_key)
            except Exception as e:
                print(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.openai_client = None
        else:
            self.openai_client = None
        
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì • (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ)
        self.data_path = Path("/app/data")
        
        # ë°ì´í„° ìºì‹œ
        self.personas_cache = None
        self.situations_cache = None
        self.product_catalog = None
    
    def load_simulation_data(self):
        """ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        try:
            print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ í™•ì¸: {self.data_path}")
            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {self.data_path.exists()}")
            
            if not self.data_path.exists():
                print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.data_path}")
                return
            
            # í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ (ìƒˆë¡œìš´ JSON í˜•ì‹)
            personas_file = self.data_path / "personas_new.json"
            print(f"ğŸ“„ í˜ë¥´ì†Œë‚˜ íŒŒì¼ ê²½ë¡œ: {personas_file}")
            print(f"ğŸ“„ í˜ë¥´ì†Œë‚˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {personas_file.exists()}")
            
            if personas_file.exists():
                with open(personas_file, 'r', encoding='utf-8') as f:
                    personas_data = json.load(f)
                    if 'personas' in personas_data:
                        self.personas_cache = personas_data['personas']
                    else:
                        self.personas_cache = personas_data if isinstance(personas_data, list) else []
            else:
                print("âŒ í˜ë¥´ì†Œë‚˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ìƒí™© ë°ì´í„° ë¡œë“œ (ìƒˆë¡œìš´ JSON í˜•ì‹)
            situations_file = self.data_path / "situations_new.json"
            print(f"ğŸ“„ ìƒí™© íŒŒì¼ ê²½ë¡œ: {situations_file}")
            print(f"ğŸ“„ ìƒí™© íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {situations_file.exists()}")
            
            if situations_file.exists():
                with open(situations_file, 'r', encoding='utf-8') as f:
                    situations_data = json.load(f)
                    if 'situations' in situations_data:
                        self.situations_cache = situations_data['situations']
                    else:
                        self.situations_cache = situations_data if isinstance(situations_data, list) else []
            else:
                print("âŒ ìƒí™© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ìƒí’ˆ ì¹´íƒˆë¡œê·¸ ë¡œë“œ
            catalog_file = self.data_path / "product_catalog.json"
            print(f"ğŸ“„ ì¹´íƒˆë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {catalog_file}")
            print(f"ğŸ“„ ì¹´íƒˆë¡œê·¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {catalog_file.exists()}")
            
            if catalog_file.exists():
                with open(catalog_file, 'r', encoding='utf-8') as f:
                    self.product_catalog = json.load(f)
                    print(f"âœ… ìƒí’ˆ ì¹´íƒˆë¡œê·¸ ë¡œë“œë¨: {len(self.product_catalog.get('products', []))}ê°œ ìƒí’ˆ")
            else:
                print("âŒ ìƒí’ˆ ì¹´íƒˆë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                self.product_catalog = {"products": [], "categories": {}}
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: í˜ë¥´ì†Œë‚˜ {len(self.personas_cache) if self.personas_cache else 0}ê°œ, "
                  f"ìƒí™© {len(self.situations_cache) if self.situations_cache else 0}ê°œ, "
                  f"ìƒí’ˆ {len(self.product_catalog.get('products', []))}ê°œ")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def get_personas(self, filters: Optional[Dict] = None) -> List[Dict]:
        """í˜ë¥´ì†Œë‚˜ ëª©ë¡ ì¡°íšŒ"""
        if not self.personas_cache:
            print("ğŸ“Š í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë”© ì¤‘...")
            self.load_simulation_data()
        
        if not self.personas_cache:
            print("âŒ í˜ë¥´ì†Œë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        personas = self.personas_cache
        
        if filters:
            # age_group í•„í„°
            if filters.get("age_group"):
                personas = [p for p in personas if p.get("age_group") == filters["age_group"]]
            
            # occupation í•„í„° - ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘
            if filters.get("occupation"):
                occupation_map = {
                    "student": "í•™ìƒ",
                    "employee": "ì§ì¥ì¸",
                    "self_employed": "ìì˜ì—…ì",
                    "retired": "ì€í‡´ì",
                    "foreigner": "ì™¸êµ­ì¸"
                }
                occupation_keyword = occupation_map.get(filters["occupation"], filters["occupation"])
                personas = [p for p in personas if occupation_keyword in p.get("occupation", "")]
            
            # type í•„í„° - ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘
            if filters.get("type"):
                type_map = {
                    "practical": "ì‹¤ìš©í˜•",
                    "conservative": "ë³´ìˆ˜í˜•",
                    "angry": "ë¶ˆë§Œí˜•",
                    "positive": "ê¸ì •í˜•",
                    "impatient": "ê¸‰í•¨í˜•"
                }
                type_keyword = type_map.get(filters["type"], filters["type"])
                personas = [p for p in personas if type_keyword in p.get("type", "")]
            
            # gender í•„í„° - ì„±ë³„ ë§¤í•‘
            if filters.get("gender"):
                gender_map = {
                    "male": "ë‚¨ì„±",
                    "female": "ì—¬ì„±"
                }
                gender_keyword = gender_map.get(filters["gender"], filters["gender"])
                personas = [p for p in personas if p.get("gender") == gender_keyword]
        
        print(f"âœ… í˜ë¥´ì†Œë‚˜ {len(personas)}ê°œ ë°˜í™˜")
        return personas
    
    def normalize_user_text(self, text: str, confidence: float = 1.0) -> Dict:
        """ì‚¬ìš©ì í…ìŠ¤íŠ¸ë¥¼ ì€í–‰ ë„ë©”ì¸ì— ë§ê²Œ ì •ê·œí™”í•©ë‹ˆë‹¤."""
        try:
            result = normalize_text(text, confidence)
            return {
                "original": result.original,
                "normalized": result.normalized,
                "corrections": result.corrections,
                "needs_clarification": result.needs_clarification,
                "extracted_entities": result.extracted_entities
            }
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ì •ê·œí™” ì‹¤íŒ¨: {e}")
            return {
                "original": text,
                "normalized": text,
                "corrections": [],
                "needs_clarification": False,
                "extracted_entities": {}
            }
    
    def match_product_catalog(self, normalized_text: str) -> List[Dict]:
        """ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ë¡œ ìƒí’ˆ ì¹´íƒˆë¡œê·¸ë¥¼ ë§¤ì¹­í•©ë‹ˆë‹¤."""
        if not self.product_catalog or not self.product_catalog.get("products"):
            return []
        
        matched_products = []
        products = self.product_catalog["products"]
        
        for product in products:
            # ìƒí’ˆëª… ì§ì ‘ ë§¤ì¹­
            if product["name"] in normalized_text:
                matched_products.append({
                    "product": product["name"],
                    "code": product["code"],
                    "category": product["category"],
                    "category_ko": product["category_ko"],
                    "match_type": "exact_name"
                })
                continue
            
            # í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = product.get("keywords", [])
            for keyword in keywords:
                if keyword in normalized_text:
                    matched_products.append({
                        "product": product["name"],
                        "code": product["code"],
                        "category": product["category"],
                        "category_ko": product["category_ko"],
                        "match_type": "keyword",
                        "matched_keyword": keyword
                    })
                    break
        
        return matched_products
    
    def expand_search_query(self, normalized_text: str, catalog_hits: List[Dict] = None) -> List[str]:
        """ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤."""
        try:
            return expand_search_query(normalized_text, catalog_hits)
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return [normalized_text]
    
    def get_business_categories(self) -> List[Dict]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ"""
        if not self.situations_cache:
            self.load_simulation_data()
        
        if not self.situations_cache:
            return []
        
        # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        categories = []
        seen_categories = set()
        
        for situation in self.situations_cache:
            title = situation.get('title', '')
            category_id = situation.get('id', '')
            
            # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "ìˆ˜ì‹  (ì˜ˆê¸ˆ, ì ê¸ˆ, ìë™ì´ì²´)" -> "ìˆ˜ì‹ ")
            if '(' in title:
                category_name = title.split('(')[0].strip()
            else:
                category_name = title
            
            if category_name not in seen_categories:
                categories.append({
                    "id": category_id,
                    "name": category_name,
                    "title": title
                })
                seen_categories.add(category_name)
        
        return categories
    
    def get_situations(self, filters: Optional[Dict] = None) -> List[Dict]:
        """ìƒí™© ëª©ë¡ ì¡°íšŒ"""
        if not self.situations_cache:
            self.load_simulation_data()
        
        if not self.situations_cache:
            return []
        
        situations = self.situations_cache
        
        if filters:
            if filters.get("category"):
                # ìƒí™© ë°ì´í„°ì—ì„œ category í•„ë“œê°€ ì—†ìœ¼ë¯€ë¡œ id í•„ë“œë¡œ ë§¤ì¹­
                category = filters["category"]
                situations = [s for s in situations if s.get("id") == category or s.get("category") == category]
        
        return situations
    
    def start_voice_simulation(self, user_id: int, persona_id: str, situation_id: str, gender: str = 'male') -> Dict:
        """ìŒì„± ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"""
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¡œë“œ
        if not self.personas_cache or not self.situations_cache:
            self.load_simulation_data()
        
        # í˜ë¥´ì†Œë‚˜ì™€ ìƒí™© ì¡°íšŒ
        persona = None
        situation = None
        
        if self.personas_cache:
            persona = next((p for p in self.personas_cache if p.get("persona_id") == persona_id), None)
            print(f"í˜ë¥´ì†Œë‚˜ ì¡°íšŒ: {persona_id} -> {persona is not None}")
        
        if self.situations_cache:
            situation = next((s for s in self.situations_cache if s.get("id") == situation_id), None)
            print(f"ìƒí™© ì¡°íšŒ: {situation_id} -> {situation is not None}")
        
        # í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©
        if not persona and self.personas_cache:
            persona = self.personas_cache[0]
            print(f"âš ï¸ í˜ë¥´ì†Œë‚˜ {persona_id}ë¥¼ ì°¾ì§€ ëª»í•´ ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ ì‚¬ìš©: {persona.get('persona_id')}")
        
        # ìƒí™©ì„ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ ì²« ë²ˆì§¸ ìƒí™© ì‚¬ìš©
        if not situation and self.situations_cache:
            situation = self.situations_cache[0]
            print(f"âš ï¸ ìƒí™© {situation_id}ë¥¼ ì°¾ì§€ ëª»í•´ ì²« ë²ˆì§¸ ìƒí™© ì‚¬ìš©: {situation.get('id')}")
        
        if not persona:
            raise ValueError(f"í˜ë¥´ì†Œë‚˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {persona_id}")
        
        if not situation:
            raise ValueError(f"ìƒí™©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {situation_id}")
        
        # ì„±ë³„ ì •ë³´ëŠ” ì´ë¯¸ í˜ë¥´ì†Œë‚˜ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
        
        # ì´ˆê¸° ê³ ê° ë©”ì‹œì§€ ìƒì„±
        initial_message_data = self._generate_initial_customer_message(persona, situation)
        
        # TTSë¡œ ìŒì„± ìƒì„±
        initial_text = initial_message_data.get("text", "ì•ˆë…•í•˜ì„¸ìš”, ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        initial_audio = self._text_to_speech(initial_text, persona)
        
        initial_message = {
            "type": "customer",
            "content": initial_text,
            "audio_url": initial_audio
        }
        
        return {
            "session_id": f"session_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "persona": {
                "id": persona["persona_id"],
                "name": persona.get("persona_id", "Unknown"),
                "gender": persona.get("gender", ""),
                "age_group": persona.get("age_group", ""),
                "occupation": persona.get("occupation", ""),
                "type": persona.get("type", ""),
                "tone": persona.get("tone", "neutral"),
                "style": persona.get("style", {}),
                "sample_utterances": persona.get("sample_utterances", [])
            },
            "situation": {
                "id": situation["id"],
                "title": situation.get("title", ""),
                "category": situation.get("category", "general"),
                "goals": situation.get("goals", []),
                "scenarios": situation.get("scenarios", [])
            },
            "initial_message": initial_message
        }
    
    def process_voice_interaction(self, session_data: Dict, audio_data: bytes, 
                                user_message: str = "") -> Dict:
        """ìŒì„± ìƒí˜¸ì‘ìš© ì²˜ë¦¬"""
        try:
            print(f"ìŒì„± ìƒí˜¸ì‘ìš© ì²˜ë¦¬ ì‹œì‘: session_data keys = {list(session_data.keys())}")
            
            if not session_data or "persona" not in session_data:
                raise ValueError("ì„¸ì…˜ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                
            persona = session_data["persona"]
            situation = session_data.get("situation", session_data.get("scenario", {}))
            
            print(f"í˜ë¥´ì†Œë‚˜: {persona.get('persona_id', persona.get('id', 'Unknown'))}")
            print(f"ìƒí™©: {situation.get('id', situation.get('scenario_id', 'Unknown'))}")
            
            # í˜ë¥´ì†Œë‚˜ì™€ ìƒí™© ì •ë³´ë¥¼ ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¡°íšŒ
            persona_id = persona.get('persona_id', persona.get('id', ''))
            situation_id = situation.get('id', situation.get('scenario_id', ''))
            
            # ì‹¤ì œ í˜ë¥´ì†Œë‚˜ì™€ ìƒí™© ë°ì´í„° ì¡°íšŒ
            actual_persona = None
            actual_situation = None
            
            if self.personas_cache and persona_id:
                actual_persona = next((p for p in self.personas_cache if p.get("persona_id") == persona_id), None)
                if actual_persona:
                    print(f"ì‹¤ì œ í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {persona_id}")
                else:
                    print(f"ì‹¤ì œ í˜ë¥´ì†Œë‚˜ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {persona_id}")
            
            if self.situations_cache and situation_id:
                actual_situation = next((s for s in self.situations_cache if s.get("id") == situation_id), None)
                if actual_situation:
                    print(f"ì‹¤ì œ ìƒí™© ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {situation_id}")
                else:
                    print(f"ì‹¤ì œ ìƒí™© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {situation_id}")
            
            # STT: ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì‚¬ìš©ìê°€ ì œê³µí•œ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
            if not user_message:
                print(f"STT ì²˜ë¦¬ ì‹œì‘: ì˜¤ë””ì˜¤ í¬ê¸° {len(audio_data) if audio_data else 0} bytes")
                transcribed_text = self._speech_to_text(audio_data)
            else:
                print(f"í…ìŠ¤íŠ¸ ì…ë ¥: '{user_message}'")
                transcribed_text = user_message
            
            print(f"ìµœì¢… í…ìŠ¤íŠ¸: '{transcribed_text}'")
            
            # STTì—ì„œ ì´ë¯¸ ì •ê·œí™”ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì²˜ë¦¬ ë¶ˆí•„ìš”
            normalized_text = transcribed_text
            corrections = []  # ì´ë¯¸ STTì—ì„œ ì²˜ë¦¬ë¨
            needs_clarification = False  # ì´ë¯¸ STTì—ì„œ ì²˜ë¦¬ë¨
            
            # 2. ìƒí’ˆ ì¹´íƒˆë¡œê·¸ ë§¤ì¹­
            print("ğŸ“‹ ìƒí’ˆ ì¹´íƒˆë¡œê·¸ ë§¤ì¹­ ì‹œì‘")
            catalog_hits = self.match_product_catalog(normalized_text)
            print(f"ì¹´íƒˆë¡œê·¸ ë§¤ì¹­ ê²°ê³¼: {len(catalog_hits)}ê°œ")
            for hit in catalog_hits:
                print(f"  - {hit['product']} ({hit['category_ko']})")
            
            # 3. RAG ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥
            print("ğŸ” RAG ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥")
            expanded_queries = self.expand_search_query(normalized_text, catalog_hits)
            print(f"í™•ì¥ëœ ì¿¼ë¦¬: {expanded_queries}")
            
            # ê³ ê° ì‘ë‹µ ìƒì„± (í”„ë¡¬í”„íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‚¬ìš©)
            print("ê³ ê° ì‘ë‹µ ìƒì„± ì‹œì‘")
            
            # ì‹¤ì œ í˜ë¥´ì†Œë‚˜ì™€ ìƒí™© ë°ì´í„° ì‚¬ìš©
            response_persona = actual_persona if actual_persona else persona
            response_situation = actual_situation if actual_situation else situation
            
            # ìƒí™© ì •ë³´ ì¶”ì¶œ (ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©)
            final_situation = response_situation
            if not final_situation or not final_situation.get('id'):
                # ê¸°ë³¸ê°’ ì‚¬ìš©
                final_situation = get_situation_defaults('deposit')
            else:
                # ìƒí™© ê¸°ë³¸ êµ¬ì¡° í™•ë³´
                final_situation = {
                    'id': final_situation.get('id', 'deposit'),
                    'title': final_situation.get('title', 'ìƒë‹´'),
                    'goals': final_situation.get('goals', ['ê³ ê° ìš”êµ¬ì‚¬í•­ íŒŒì•…', 'í•µì‹¬ ì •ë³´ ì•ˆë‚´']),
                    'required_slots': final_situation.get('required_slots', []),
                    'forbidden_claims': final_situation.get('forbidden_claims', []),
                    'style_rules': final_situation.get('style_rules', ['ìˆ«ìëŠ” ì˜ˆì‹œë¡œë§Œ', 'í™•ì¸ í›„ ì•ˆë‚´']),
                    'disclaimer': final_situation.get('disclaimer', 'ì‹¤ì œ ì¡°ê±´ì€ ì •ì±…ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
                }
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„± (ì„¸ì…˜ ë°ì´í„°ì—ì„œ ì¶”ì¶œ ë° ëˆ„ì )
            conversation_history = session_data.get("conversation_history", [])
            
            # ì´ˆê¸° ë©”ì‹œì§€ê°€ ìˆê³  íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¶”ê°€
            if session_data.get("initial_message") and not conversation_history:
                initial_msg = session_data["initial_message"]
                conversation_history.append({
                    "role": "customer", 
                    "text": initial_msg.get("content", ""),
                    "timestamp": datetime.now().isoformat()
                })
            
            # í˜„ì¬ ì§ì› ë°œí™”ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            conversation_history.append({
                "role": "employee", 
                "text": transcribed_text,
                "timestamp": datetime.now().isoformat()
            })
            
            print(f"ëŒ€í™” íˆìŠ¤í† ë¦¬: {len(conversation_history)}í„´")
            for i, msg in enumerate(conversation_history[-4:]):
                print(f"  {i+1}. {msg.get('role', 'unknown')}: {msg.get('text', '')[:50]}...")
            
            # ë‹¬ì„±ëœ ëª©í‘œ ì •ë³´ ì¶”ì¶œ (ì„¸ì…˜ ë°ì´í„°ì—ì„œ)
            achieved_goals = session_data.get("achieved_goals", [])  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë¶„ì„í•œ ê²°ê³¼
            
            # ê³ ê° ê°ì •í˜• ì¶”ì¶œ (í˜ë¥´ì†Œë‚˜ ë˜ëŠ” ì„¸ì…˜ ë°ì´í„°ì—ì„œ)
            customer_emotion = response_persona.get("type", "ê¸ì •í˜•") if response_persona else "ê¸ì •í˜•"
            if "customer_emotion" in session_data:
                customer_emotion = session_data["customer_emotion"]
            
            # ìµœê·¼ ì§ì› ì§ˆë¬¸ ì¶”ì¶œ (íˆìŠ¤í† ë¦¬ì—ì„œ)
            last_employee_questions = []
            for msg in conversation_history[-5:]:  # ìµœê·¼ 5í„´ í™•ì¸
                if msg.get("role") == "employee":
                    text = msg.get("text", "")
                    if "?" in text or "?" in text or "ì–´ë–»ê²Œ" in text or "ë¬´ì—‡" in text:
                        last_employee_questions.append(text)
            
            # í”„ë¡¬í”„íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ë¡œ ë©”ì‹œì§€ êµ¬ì„±
            messages = compose_llm_messages(
                persona=response_persona,
                situation=final_situation,
                user_text=normalized_text,  # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                rag_hits=[],  # TODO: RAG ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
                history=conversation_history[-10:],  # ìµœê·¼ 10í„´ê¹Œì§€ ì „ë‹¬ (ë” ë§ì€ ë§¥ë½)
                extras={
                    "userText_raw": transcribed_text,  # ì›ë³¸ í…ìŠ¤íŠ¸
                    "corrections": corrections,  # êµì • ì •ë³´
                    "catalogHits": catalog_hits,  # ì¹´íƒˆë¡œê·¸ ë§¤ì¹­ ê²°ê³¼
                    "needs_clarification": needs_clarification,  # ì¬í™•ì¸ í•„ìš” ì—¬ë¶€
                    "expanded_queries": expanded_queries,  # í™•ì¥ëœ ê²€ìƒ‰ ì¿¼ë¦¬
                    "achieved_goals": achieved_goals,  # ë‹¬ì„±ëœ ëª©í‘œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
                    "customer_emotion": customer_emotion,  # ê³ ê° ê°ì •í˜•
                    "last_employee_questions": last_employee_questions,  # ìµœê·¼ ì§ì› ì§ˆë¬¸ ëª©ë¡
                    "stuck_counter": session_data.get("stuck_counter", 0),  # ë°˜ë³µ ì¹´ìš´í„°
                    "should_close": session_data.get("should_close", False)  # ë§ˆë¬´ë¦¬ ì‹ í˜¸
                }
            )
            
            # OpenAI API í˜¸ì¶œ
            llm_response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.2,
                max_tokens=500
            )
            
            # LLM ì‘ë‹µ íŒŒì‹±
            content = llm_response.choices[0].message.content
            parsed = parse_llm_response(content)
            
            print(f"ê³ ê° ì‘ë‹µ (script): '{parsed.get('script', '')}'")
            
            # ê³ ê° ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            customer_response_text = parsed.get('script', '')
            conversation_history.append({
                "role": "customer",
                "text": customer_response_text,
                "timestamp": datetime.now().isoformat()
            })
            
            # TTS: ê³ ê° ì‘ë‹µì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜
            print(f"TTS ì²˜ë¦¬ ì‹œì‘")
            customer_audio = self._text_to_speech(customer_response_text, response_persona)
            print(f"TTS ì™„ë£Œ: ì˜¤ë””ì˜¤ ê¸¸ì´ {len(customer_audio) if customer_audio else 0}")
            
            # ì‘ë‹µ í‰ê°€
            evaluation = self._evaluate_user_response(transcribed_text, actual_persona or persona, actual_situation or situation)
            
            result = {
                "transcribed_text": transcribed_text,
                "customer_response": customer_response_text,
                "customer_audio": customer_audio,
                "feedback": evaluation,
                "followups": parsed.get('followups', []),
                "safety_notes": parsed.get('safety_notes', ''),
                "conversation_phase": "ongoing",
                "session_score": self._calculate_session_score(session_data),
                "conversation_history": conversation_history  # ì—…ë°ì´íŠ¸ëœ íˆìŠ¤í† ë¦¬ í¬í•¨
            }
            
            print("ìŒì„± ìƒí˜¸ì‘ìš© ì²˜ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            print(f"ìŒì„± ìƒí˜¸ì‘ìš© ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _speech_to_text(self, audio_data: bytes) -> str:
        """í•˜ì´ë¸Œë¦¬ë“œ STT: whisper ê¸°ë³¸ + gpt-4o-transcribe ë³´ì •ìš©"""
        if not self.openai_client:
            return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            
        if not audio_data:
            return "ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

        try:
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".webm")
            audio_file.write(audio_data)
            audio_file.close()
            
            print(f"STT ì²˜ë¦¬: ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸° {len(audio_data)} bytes")
            
            # 1ë‹¨ê³„: whisper-1ë¡œ ê¸°ë³¸ ì¸ì‹
            print("ğŸ¤ 1ë‹¨ê³„: whisper-1 ê¸°ë³¸ ì¸ì‹")
            with open(audio_file.name, "rb") as f:
                transcript = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=f,
                    language="ko"
                )
            
            initial_text = transcript.text
            print(f"ì´ˆê¸° ì¸ì‹ ê²°ê³¼: '{initial_text}'")
            
            # 2ë‹¨ê³„: ì˜ë¯¸ ë³´ì •ìœ¼ë¡œ í’ˆì§ˆ í‰ê°€
            normalize_result = self.normalize_user_text(initial_text, confidence=0.8)
            corrections = normalize_result["corrections"]
            needs_clarification = normalize_result["needs_clarification"]
            
            print(f"êµì • íšŸìˆ˜: {len(corrections)}")
            print(f"ì¬í™•ì¸ í•„ìš”: {needs_clarification}")
            
            # 3ë‹¨ê³„: í’ˆì§ˆì´ ë‚®ìœ¼ë©´ gpt-4o-transcribeë¡œ ì¬ì¸ì‹
            should_reprocess = (
                len(corrections) >= 2 or  # êµì •ì´ 2ê°œ ì´ìƒ
                needs_clarification or   # ì¬í™•ì¸ í•„ìš”
                len(initial_text) < 3     # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸
            )
            
            if should_reprocess:
                print("ğŸ”„ 2ë‹¨ê³„: gpt-4o-transcribe ì¬ì¸ì‹ (í’ˆì§ˆ ê°œì„ )")
                with open(audio_file.name, "rb") as f:
                    enhanced_transcript = self.openai_client.audio.transcriptions.create(
                        model="gpt-4o-transcribe",
                        file=f,
                        language="ko"
                    )
                
                enhanced_text = enhanced_transcript.text
                print(f"ê°œì„ ëœ ì¸ì‹ ê²°ê³¼: '{enhanced_text}'")
                
                # ê°œì„ ëœ ê²°ê³¼ë¡œ ë‹¤ì‹œ ì •ê·œí™”
                final_normalize = self.normalize_user_text(enhanced_text, confidence=0.9)
                final_text = final_normalize["normalized"]
                
                print(f"ìµœì¢… ì •ê·œí™”: '{final_text}'")
                os.unlink(audio_file.name)
                return final_text
            else:
                print("âœ… whisper-1 ê²°ê³¼ ì‚¬ìš© (í’ˆì§ˆ ì–‘í˜¸)")
                os.unlink(audio_file.name)
                return normalize_result["normalized"]
            
        except Exception as e:
            print(f"STT ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def _text_to_speech(self, text: str, persona: Dict) -> str:
        """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜ (TTS) - gpt-4o-mini-tts ì‚¬ìš©"""
        if not self.openai_client:
            print("TTS ì˜¤ë¥˜: OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return ""
            
        if not text:
            print("TTS ì˜¤ë¥˜: ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
            
        try:
            print(f"TTS ì‹œì‘: '{text[:50]}...'")

            # í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì‚°ì¶œ
            params = get_voice_params(persona)
            print(f"TTS íŒŒë¼ë¯¸í„°: {params}")

            # OpenAI TTS API í˜¸ì¶œ (gpt-4o-mini-tts ëª¨ë¸ ì‚¬ìš©, ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë§Œ)
            response = self.openai_client.audio.speech.create(
                model="gpt-4o-mini-tts",
                voice=params["voice"],
                speed=params["rate"],  # speed íŒŒë¼ë¯¸í„° ì‚¬ìš©
                input=text  # SSML ëŒ€ì‹  ì¼ë°˜ í…ìŠ¤íŠ¸ ì‚¬ìš©
            )

            audio_data = response.content
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            print(f"TTS ì„±ê³µ: {len(audio_data)} bytes")

            return f"data:audio/mpeg;base64,{audio_base64}"
            
        except Exception as e:
            print(f"TTS ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _get_voice_characteristics(self, persona: Dict) -> Dict:
        """í˜ë¥´ì†Œë‚˜ì— ë”°ë¥¸ ìŒì„± íŠ¹ì„± ì„¤ì • (ì„±ë³„, ë‚˜ì´ëŒ€, ê³ ê°íƒ€ì… ê¸°ë°˜)"""
        customer_type = persona.get("type", "ì‹¤ìš©í˜•")
        age_group = persona.get("age_group", "30ëŒ€")
        gender = persona.get("gender", "ë‚¨ì„±")
        
        # ì„±ë³„ íŒë‹¨
        is_female = (gender == "ì—¬ì„±" or gender == "female")
        
        print(f"ğŸ¤ í˜ë¥´ì†Œë‚˜ ìŒì„± ì„¤ì •: {gender} {age_group} {customer_type}")
        
        # ê³ ê° íƒ€ì…ë³„ ìŒì„± í†¤ ë§¤í•‘
        tone_map = {
            "ì‹¤ìš©í˜•": "direct",
            "ë³´ìˆ˜í˜•": "calm",
            "ë¶ˆë§Œí˜•": "tense",
            "ê¸ì •í˜•": "cheerful",
            "ê¸‰í•¨í˜•": "urgent"
        }
        
        tone = tone_map.get(customer_type, "neutral")
        
        # ì„±ë³„ + ë‚˜ì´ëŒ€ + í†¤ë³„ ìŒì„± ì„ íƒ
        if is_female:
            # ì—¬ì„± ìŒì„±: nova(ì°¨ë¶„), shimmer(ë°ìŒ)
            if age_group in ["20ëŒ€", "30ëŒ€"]:
                voice_map = {
                    "direct": "shimmer",    # ì Šê³  ì§ì„¤ì 
                    "calm": "nova",         # ì°¨ë¶„í•˜ê³  ì‹ ì¤‘
                    "tense": "shimmer",     # ì•½ê°„ ë‚ ì¹´ë¡œìš´ í†¤
                    "cheerful": "shimmer",  # ë°ê³  ê¸ì •ì 
                    "urgent": "shimmer",    # ë¹ ë¥´ê³  ê¸‰í•œ
                    "neutral": "nova"
                }
            else:  # 40ëŒ€ ì´ìƒ
                voice_map = {
                    "direct": "nova",       # ì„±ìˆ™í•˜ê³  ì§ì„¤ì 
                    "calm": "nova",         # ì°¨ë¶„í•˜ê³  ì‹ ì¤‘
                    "tense": "nova",        # ì°¨ë¶„í•˜ì§€ë§Œ ë¶ˆë§Œ
                    "cheerful": "nova",     # ë”°ëœ»í•˜ê³  ê¸ì •ì 
                    "urgent": "shimmer",    # ê¸‰í•œ ìƒí™©
                    "neutral": "nova"
                }
        else:
            # ë‚¨ì„± ìŒì„±: alloy(ì¤‘ì„±ì ), echo(ê¹ŠìŒ), fable(ë”°ëœ»í•¨)
            if age_group in ["20ëŒ€", "30ëŒ€"]:
                voice_map = {
                    "direct": "alloy",      # ì Šê³  ì§ì„¤ì 
                    "calm": "echo",         # ì°¨ë¶„í•˜ê³  ê¹Šì€
                    "tense": "fable",       # ì•½ê°„ ê±°ì¹œ í†¤
                    "cheerful": "fable",    # ë°ê³  ì¹œê·¼í•œ
                    "urgent": "alloy",      # ë¹ ë¥´ê³  ê¸‰í•œ
                    "neutral": "alloy"
                }
            else:  # 40ëŒ€ ì´ìƒ
                voice_map = {
                    "direct": "echo",       # ì„±ìˆ™í•˜ê³  ì§ì„¤ì 
                    "calm": "echo",         # ì°¨ë¶„í•˜ê³  ì‹ ì¤‘
                    "tense": "fable",       # ë¶ˆë§ŒìŠ¤ëŸ¬ìš´ í†¤
                    "cheerful": "fable",    # ë”°ëœ»í•˜ê³  ê¸ì •ì 
                    "urgent": "alloy",      # ê¸‰í•œ ìƒí™©
                    "neutral": "echo"
                }
        
        # ê³ ê° íƒ€ì…ë³„ ë§í•˜ê¸° ì†ë„
        speed_map = {
            "direct": 1.1,      # ì‹¤ìš©í˜•: ë¹ ë¥´ê²Œ
            "calm": 0.9,        # ë³´ìˆ˜í˜•: ì²œì²œíˆ
            "tense": 1.0,       # ë¶ˆë§Œí˜•: ë³´í†µ
            "cheerful": 1.1,    # ê¸ì •í˜•: ë°ê²Œ ë¹ ë¥´ê²Œ
            "urgent": 1.3,      # ê¸‰í•¨í˜•: ë§¤ìš° ë¹ ë¥´ê²Œ
            "neutral": 1.0
        }
        
        voice = voice_map.get(tone, "alloy")
        
        return {
            "voice": voice,
            "speed": speed_map.get(tone, 1.0)
        }
    
    def _generate_initial_customer_message(self, persona: Dict, situation: Dict) -> Dict:
        """ì´ˆê¸° ê³ ê° ë©”ì‹œì§€ ìƒì„±"""
        sample_utterances = persona.get("sample_utterances", [])
        
        # RAG ê¸°ë°˜ ì´ˆê¸° ë©”ì‹œì§€ ìƒì„±
        rag_context = self._get_rag_context(situation)
        
        prompt = f"""
        ë‹¹ì‹ ì€ {persona.get('persona_id', 'Unknown')} ê³ ê°ì…ë‹ˆë‹¤.
        
        ê³ ê° ì •ë³´:
        - ì—°ë ¹ëŒ€: {persona.get('age_group', '')}
        - ì§ì—…: {persona.get('occupation', '')}
        - ê¸ˆìœµ ì´í•´ë„: {persona.get('financial_literacy', '')}
        - ì„±ê²©: {persona.get('type', '')}
        - í†¤: {persona.get('tone', 'neutral')}
        - ë§í•˜ê¸° ìŠ¤íƒ€ì¼: {persona.get('style', {})}
        - ì˜ˆì‹œ ë°œí™”: {sample_utterances}
        
        ìƒí™©: {situation.get('title', '')}
        
        RAG ì»¨í…ìŠ¤íŠ¸:
        {rag_context}
        
        ì—…ë¬´ ì¹´í…Œê³ ë¦¬: {situation.get('category', situation.get('title', '')).split(' ')[0]}
        ì„¸ë¶€ ìƒí™©: {situation.get('goals', [])}
        ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­: {situation.get('title', '')}
        
        ì´ ìƒí™©ì—ì„œ ê³ ê°ì´ ì€í–‰ ì§ì›ì—ê²Œ ì²˜ìŒìœ¼ë¡œ ë§í•  ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        - ê³ ê°ì˜ ì„±ê²©ê³¼ ìƒí™©ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
        - ì—…ë¬´ ì¹´í…Œê³ ë¦¬ì™€ ì„¸ë¶€ ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­
        - í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200
            )
            
            return {
                "text": response.choices[0].message.content,
                "phase": "initial"
            }
            
        except Exception as e:
            print(f"ì´ˆê¸° ë©”ì‹œì§€ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "text": sample_utterances[0] if sample_utterances else "ì•ˆë…•í•˜ì„¸ìš”, ë„ì›€ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "phase": "initial"
            }
    
    def _generate_customer_response_with_rag(self, user_message: str, persona: Dict, 
                                           situation: Dict) -> Dict:
        """RAG ê¸°ë°˜ ê³ ê° ì‘ë‹µ ìƒì„±"""
        # RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        rag_context = self._get_rag_context(situation)
        
        # í˜ë¥´ì†Œë‚˜ íŠ¹ì„± ì¶”ì¶œ
        persona_traits = self._extract_persona_traits(persona)
        
        prompt = f"""
        ë‹¹ì‹ ì€ {persona.get('persona_id', 'Unknown')} ê³ ê°ì…ë‹ˆë‹¤.
        
        ê³ ê° íŠ¹ì„±:
        {persona_traits}
        
        ìƒí™©: {situation.get('title', '')}
        ëŒ€í™” í”Œë¡œìš°: {situation.get('scenarios', [])}
        
        RAG ì»¨í…ìŠ¤íŠ¸:
        {rag_context}
        
        ì€í–‰ ì§ì›ì´ "{user_message}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.
        
        ì´ ìƒí™©ì—ì„œ ê³ ê°ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•  ë‚´ìš©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê³ ê°ì˜ ì„±ê²©ê³¼ ìƒí™©ì— ë§ëŠ” ë°˜ì‘ì„ ë³´ì—¬ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300
            )
            
            return {
                "text": response.choices[0].message.content,
                "phase": self._determine_conversation_phase(situation)
            }
            
        except Exception as e:
            print(f"ê³ ê° ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "text": "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤.",
                "phase": "ongoing"
            }
    
    def _get_rag_context(self, situation: Dict) -> str:
        """ìƒí™© ê¸°ë°˜ RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context_parts = []
        
        # ìƒí™© ì •ë³´
        context_parts.append(f"ìƒí™©: {situation.get('title', '')}")
        
        # ìƒí™© ì„¸ë¶€ ì •ë³´
        context_parts.append(f"\nì—…ë¬´ ìƒí™©:")
        context_parts.append(f"- ì¹´í…Œê³ ë¦¬: {situation.get('category', '')}")
        context_parts.append(f"- ëª©í‘œ: {situation.get('goals', [])}")
        context_parts.append(f"- ì‹œë‚˜ë¦¬ì˜¤: {situation.get('scenarios', [])}")
        
        # ì¶”ê°€ ì •ë³´ (í•„ìš”ì‹œ)
        if situation.get('required_slots'):
            context_parts.append(f"\ní•„ìš” ì •ë³´: {situation.get('required_slots', [])}")
        if situation.get('style_rules'):
            context_parts.append(f"\nìŠ¤íƒ€ì¼ ê·œì¹™: {situation.get('style_rules', [])}")
        
        return "\n".join(context_parts)
    
    def _extract_persona_traits(self, persona: Dict) -> str:
        """í˜ë¥´ì†Œë‚˜ íŠ¹ì„± ì¶”ì¶œ"""
        traits = []
        
        traits.append(f"- ì—°ë ¹ëŒ€: {persona.get('age_group', '')}")
        traits.append(f"- ì§ì—…: {persona.get('occupation', '')}")
        traits.append(f"- ê¸ˆìœµ ì´í•´ë„: {persona.get('financial_literacy', '')}")
        traits.append(f"- ê³ ê° íƒ€ì…: {persona.get('type', '')}")
        traits.append(f"- í†¤: {persona.get('tone', 'neutral')}")
        
        style = persona.get('style', {})
        if style:
            traits.append(f"- ë§í•˜ê¸° ìŠ¤íƒ€ì¼: {style}")
        
        notes = persona.get('notes', '')
        if notes:
            traits.append(f"- íŠ¹ì´ì‚¬í•­: {notes}")
        
        sample_utterances = persona.get('sample_utterances', [])
        if sample_utterances:
            traits.append(f"- ì˜ˆì‹œ ë°œí™”: {sample_utterances}")
        
        return "\n".join(traits)
    
    def _determine_conversation_phase(self, situation: Dict) -> str:
        """ëŒ€í™” ë‹¨ê³„ ê²°ì •"""
        scenarios = situation.get('scenarios', [])
        
        if len(scenarios) <= 2:
            return "initial"
        elif len(scenarios) <= 4:
            return "developing"
        else:
            return "concluding"
    
    def _evaluate_user_response(self, user_message: str, persona: Dict, situation: Dict) -> str:
        """ì‚¬ìš©ì ì‘ë‹µ í‰ê°€"""
        scenarios = situation.get('scenarios', [])
        
        if not scenarios:
            return "í‰ê°€ ê¸°ì¤€ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        scenarios_text = "\n".join([
            f"- {scenario}"
            for scenario in scenarios
        ])
        
        prompt = f"""
        ì€í–‰ ì§ì›ì˜ ì‘ë‹µ: "{user_message}"
        
        ê³ ê° ì •ë³´:
        - ê³ ê° íƒ€ì…: {persona.get('type', '')}
        - ê¸ˆìœµ ì´í•´ë„: {persona.get('financial_literacy', '')}
        - í†¤: {persona.get('tone', 'neutral')}
        
        ì‹œë‚˜ë¦¬ì˜¤:
        {scenarios_text}
        
        ì´ ì‘ë‹µì´ ê³ ê°ì—ê²Œ ì ì ˆí–ˆëŠ”ì§€ í‰ê°€í•˜ê³ , ê°œì„ ì ì´ ìˆë‹¤ë©´ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"ì‘ë‹µ í‰ê°€ ì˜¤ë¥˜: {e}")
            return "ì‘ë‹µ í‰ê°€ë¥¼ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _calculate_session_score(self, session_data: Dict) -> float:
        """ì„¸ì…˜ ì ìˆ˜ ê³„ì‚° (ì„ì‹œ êµ¬í˜„)"""
        # ì‹¤ì œë¡œëŠ” ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°í•´ì•¼ í•¨
        return 75.0
    
<<<<<<< HEAD
    def generate_comprehensive_feedback(self, conversation_history: List[Dict], 
                                      persona: Dict, situation: Dict) -> Dict:
        """
        6ê°€ì§€ ì—­ëŸ‰ ê¸°ë°˜ ì¢…í•© í‰ê°€ ë° í”¼ë“œë°± ìƒì„±
        - ì§€ì‹ (Knowledge): ìƒí’ˆ/ì„œë¹„ìŠ¤ì— ëŒ€í•œ ì •í™•ì„±ê³¼ ì „ë¬¸ì„±
        - ê¸°ìˆ  (Skill): ìƒë‹´ í”„ë¡œì„¸ìŠ¤ì™€ íë¦„ ì¤€ìˆ˜
        - ê³µê°ë„ (Empathy): ê³ ê° ìƒí™© ì´í•´ ë° ê³µê° í‘œí˜„
        - ëª…í™•ì„± (Clarity): ì„¤ëª…ì˜ ëª…ë£Œí•¨ê³¼ ì´í•´í•˜ê¸° ì‰¬ì›€
        - ì¹œì ˆë„ (Kindness): ì˜ˆì˜ì™€ ë°°ë ¤
        - ìì‹ ê° (Confidence): í™•ì‹ ìˆê³  ì „ë¬¸ì ì¸ ì–´íˆ¬
        """
        try:
            # ì§ì› ë°œí™”ë§Œ ì¶”ì¶œ (í‰ê°€ ëŒ€ìƒ)
            employee_utterances = [
                msg['text'] for msg in conversation_history 
                if msg.get('role') == 'employee'
            ]
            
            if not employee_utterances:
                return self._get_default_feedback()
            
            # ì „ì²´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
            conversation_context = "\n".join([
                f"{'ê³ ê°' if msg.get('role') == 'customer' else 'ì§ì›'}: {msg.get('text', '')}"
                for msg in conversation_history
            ])
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ 6ê°€ì§€ ì—­ëŸ‰ í‰ê°€
            evaluation_prompt = f"""
ë‹¹ì‹ ì€ ì€í–‰ ì§ì›ì˜ ê³ ê° ì‘ëŒ€ ì—­ëŸ‰ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ 6ê°€ì§€ ì—­ëŸ‰ì„ í‰ê°€í•˜ê³  êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.

í‰ê°€ ê¸°ì¤€:
1. ì§€ì‹ (Knowledge): ìƒí’ˆ/ì„œë¹„ìŠ¤ ì„¤ëª…ì˜ ì •í™•ì„±, ì „ë¬¸ì„± (0-100ì )
2. ê¸°ìˆ  (Skill): ìƒë‹´ í”„ë¡œì„¸ìŠ¤ ì¤€ìˆ˜ (ì§ˆë¬¸â†’ì‘ë‹µâ†’í™•ì¸ íë¦„) (0-100ì )
3. ê³µê°ë„ (Empathy): ê³ ê° ìƒí™© ì´í•´ ë° ê³µê° í‘œí˜„ (0-100ì )
4. ëª…í™•ì„± (Clarity): ì„¤ëª…ì˜ ëª…ë£Œí•¨, ì´í•´í•˜ê¸° ì‰¬ì›€ (0-100ì )
5. ì¹œì ˆë„ (Kindness): ì˜ˆì˜, ë°°ë ¤, ì •ì¤‘í•œ í‘œí˜„ (0-100ì )
6. ìì‹ ê° (Confidence): í™•ì‹ ìˆê³  ì „ë¬¸ì ì¸ ì–´íˆ¬ (0-100ì )

ê³ ê° ì •ë³´:
- ìœ í˜•: {persona.get('type', '')}
- ê¸ˆìœµ ì´í•´ë„: {persona.get('financial_literacy', '')}

ìƒë‹´ ìƒí™©:
- ì œëª©: {situation.get('title', '')}
- ëª©í‘œ: {situation.get('goals', [])}

ëŒ€í™” ë‚´ìš©:
{conversation_context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "knowledge": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "skill": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "empathy": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "clarity": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "kindness": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "confidence": {{
        "score": <0-100 ì ìˆ˜>,
        "feedback": "<êµ¬ì²´ì ì¸ í”¼ë“œë°±>"
    }},
    "summary": "<ì „ë°˜ì ì¸ í‰ê°€ ìš”ì•½>",
    "improvements": "<ê°œì„  ì œì•ˆ>"
}}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": evaluation_prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            # JSON íŒŒì‹±
            content = response.choices[0].message.content
            # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•ì‹ ì²˜ë¦¬)
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            evaluation = json.loads(content)
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° (6ê°€ì§€ ì—­ëŸ‰ì˜ í‰ê· )
            scores = [
                evaluation['knowledge']['score'],
                evaluation['skill']['score'],
                evaluation['empathy']['score'],
                evaluation['clarity']['score'],
                evaluation['kindness']['score'],
                evaluation['confidence']['score']
            ]
            overall_score = sum(scores) / len(scores)
            
            # ë“±ê¸‰ ì‚°ì •
            if overall_score >= 90:
                grade = 'A'
                performance_level = 'íƒì›”í•œ ì„±ê³¼'
            elif overall_score >= 80:
                grade = 'B'
                performance_level = 'ìš°ìˆ˜í•œ ì„±ê³¼'
            elif overall_score >= 70:
                grade = 'C'
                performance_level = 'ì–‘í˜¸í•œ ì„±ê³¼'
            elif overall_score >= 60:
                grade = 'D'
                performance_level = 'ë³´í†µ ìˆ˜ì¤€'
            else:
                grade = 'F'
                performance_level = 'ê°œì„  í•„ìš”'
            
            return {
                "overallScore": round(overall_score, 1),
                "grade": grade,
                "performanceLevel": performance_level,
                "summary": evaluation.get('summary', 'í‰ê°€ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.'),
                "competencies": [
                    {"name": "ì§€ì‹", "score": evaluation['knowledge']['score'], "maxScore": 100},
                    {"name": "ê¸°ìˆ ", "score": evaluation['skill']['score'], "maxScore": 100},
                    {"name": "ê³µê°ë„", "score": evaluation['empathy']['score'], "maxScore": 100},
                    {"name": "ëª…í™•ì„±", "score": evaluation['clarity']['score'], "maxScore": 100},
                    {"name": "ì¹œì ˆë„", "score": evaluation['kindness']['score'], "maxScore": 100},
                    {"name": "ìì‹ ê°", "score": evaluation['confidence']['score'], "maxScore": 100}
                ],
                "detailedFeedback": {
                    "knowledge": evaluation['knowledge'],
                    "skill": evaluation['skill'],
                    "empathy": evaluation['empathy'],
                    "clarity": evaluation['clarity'],
                    "kindness": evaluation['kindness'],
                    "confidence": evaluation['confidence']
                },
                "improvements": evaluation.get('improvements', 'ì§€ì†ì ì¸ ì—°ìŠµì„ í†µí•´ ê°œì„ í•˜ì„¸ìš”.')
            }
            
        except Exception as e:
            print(f"âŒ ì¢…í•© í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return self._get_default_feedback()
    
    def _get_default_feedback(self) -> Dict:
        """ê¸°ë³¸ í”¼ë“œë°± (ì˜¤ë¥˜ ë°œìƒ ì‹œ)"""
        return {
            "overallScore": 70.0,
            "grade": "C",
            "performanceLevel": "ì–‘í˜¸í•œ ì„±ê³¼",
            "summary": "ì‹œë®¬ë ˆì´ì…˜ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë” ë§ì€ ì—°ìŠµì„ í†µí•´ ì—­ëŸ‰ì„ í–¥ìƒì‹œì¼œë³´ì„¸ìš”.",
            "competencies": [
                {"name": "ì§€ì‹", "score": 70, "maxScore": 100},
                {"name": "ê¸°ìˆ ", "score": 70, "maxScore": 100},
                {"name": "ê³µê°ë„", "score": 70, "maxScore": 100},
                {"name": "ëª…í™•ì„±", "score": 70, "maxScore": 100},
                {"name": "ì¹œì ˆë„", "score": 70, "maxScore": 100},
                {"name": "ìì‹ ê°", "score": 70, "maxScore": 100}
            ],
            "detailedFeedback": {
                "knowledge": {"score": 70, "feedback": "ê¸°ë³¸ì ì¸ ì§€ì‹ì€ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤."},
                "skill": {"score": 70, "feedback": "ìƒë‹´ íë¦„ì„ ì˜ ë”°ë¥´ê³  ìˆìŠµë‹ˆë‹¤."},
                "empathy": {"score": 70, "feedback": "ê³ ê°ì—ê²Œ ê³µê°í•˜ëŠ” íƒœë„ë¥¼ ë³´ì…ë‹ˆë‹¤."},
                "clarity": {"score": 70, "feedback": "ì„¤ëª…ì´ ëŒ€ì²´ë¡œ ëª…í™•í•©ë‹ˆë‹¤."},
                "kindness": {"score": 70, "feedback": "ì¹œì ˆí•œ ì‘ëŒ€ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤."},
                "confidence": {"score": 70, "feedback": "ìì‹ ê°ìˆëŠ” ì–´íˆ¬ë¥¼ ìœ ì§€í•˜ì„¸ìš”."}
            },
            "improvements": "ì§€ì†ì ì¸ ì—°ìŠµì„ í†µí•´ ì—­ëŸ‰ì„ í–¥ìƒì‹œì¼œë³´ì„¸ìš”."
        }
    
    def analyze_goal_achievement(
        self,
        conversation_history: List[Dict],
        goals: List[str]
    ) -> List[int]:
        """
        ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë‹¬ì„±ëœ ëª©í‘œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        
        Args:
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì˜ˆ: [{"role": "user", "text": "..."}, ...])
            goals: ëª©í‘œ ëª©ë¡ (ì˜ˆ: ["ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ íŒŒì•…", "ì ì ˆí•œ ìƒí’ˆ ì¶”ì²œ", ...])
        
        Returns:
            ë‹¬ì„±ëœ ëª©í‘œì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [0, 2])
        """
        if not self.openai_client:
            print("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        if not goals or not conversation_history:
            return []
        
        # ì „ì²´ ëŒ€í™” ë‚´ìš© ì¶”ì¶œ (ê³ ê°ê³¼ ì§ì› ëª¨ë‘ í¬í•¨)
        conversation_parts = []
        for msg in conversation_history:
            role = msg.get("role", "")
            text = msg.get("text", "")
            if role == "user":
                conversation_parts.append(f"ì§ì›: {text}")
            elif role == "customer":
                conversation_parts.append(f"ê³ ê°: {text}")
        
        if not conversation_parts:
            return []
        
        # ëŒ€í™” ë‚´ìš© ìš”ì•½ (ì „ì²´ ë§¥ë½ í¬í•¨)
        conversation_text = "\n".join(conversation_parts)
        
        # ëª©í‘œ ëª©ë¡ ë¬¸ìì—´ ìƒì„±
        goals_text = "\n".join([
            f"{i}. {goal}"
            for i, goal in enumerate(goals)
        ])
        
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¹ì‹ ì€ ì€í–‰ ì§ì›ì˜ ê³ ê° ìƒë‹´ ëŒ€í™”ë¥¼ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì€í–‰ ì§ì›ê³¼ ê³ ê°ì˜ ì „ì²´ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:
---
{conversation_text}
---

ë‹¤ìŒì€ ì´ ìƒë‹´ì—ì„œ ë‹¬ì„±í•´ì•¼ í•˜ëŠ” ëª©í‘œ ëª©ë¡ì…ë‹ˆë‹¤:
---
{goals_text}
---

ìœ„ ëŒ€í™” ë‚´ìš©ì„ ìì„¸íˆ ë¶„ì„í•˜ì—¬, ê° ëª©í‘œê°€ ë‹¬ì„±ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

**íŒë‹¨ ê¸°ì¤€:**
- ëª©í‘œì˜ í•µì‹¬ ë‚´ìš©ì´ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ë˜ê±°ë‚˜ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
- ì˜ˆë¥¼ ë“¤ì–´, "ê³ ê° ë¶ˆë§Œ ê²½ì²­ ë° ê³µê°" ëª©í‘œëŠ” ì§ì›ì´ ê³ ê°ì˜ ë¶ˆë§Œì„ ë“£ê³  ê³µê° í‘œí˜„(ì˜ˆ: "ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤", "ì´í•´í•˜ê² ìŠµë‹ˆë‹¤")ì„ í–ˆëŠ”ì§€ í™•ì¸
- "ë¬¸ì œ ìš”ì•½ ë° í•´ê²° ì ˆì°¨ ì•ˆë‚´" ëª©í‘œëŠ” ì§ì›ì´ ë¬¸ì œë¥¼ ì •ë¦¬í•˜ê³  í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í–ˆëŠ”ì§€ í™•ì¸
- ë¶€ë¶„ì ìœ¼ë¡œë§Œ ë‹¬ì„±ëœ ê²½ìš°ë„ ë‹¬ì„±ìœ¼ë¡œ ê°„ì£¼ (ì™„ë²½í•˜ì§€ ì•Šì•„ë„ ë¨)

ì¶œë ¥ í˜•ì‹:
ë‹¬ì„±ëœ ëª©í‘œ ë²ˆí˜¸ë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, 0ë²ˆê³¼ 2ë²ˆ ëª©í‘œê°€ ë‹¬ì„±ë˜ì—ˆë‹¤ë©´:
0,2

ë‹¬ì„±ëœ ëª©í‘œê°€ í•˜ë‚˜ë„ ì—†ë‹¤ë©´:
ì—†ìŒ

ë‹¬ì„±ëœ ëª©í‘œ ë²ˆí˜¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.3  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì€ temperature ì‚¬ìš©
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # ê²°ê³¼ íŒŒì‹±
            if result_text.lower() in ["ì—†ìŒ", "none", "ì—†ìŠµë‹ˆë‹¤", ""]:
                return []
            
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ìˆ«ìë“¤ ì¶”ì¶œ
            achieved_indices = []
            for part in result_text.split(","):
                part = part.strip()
                try:
                    index = int(part)
                    if 0 <= index < len(goals):
                        achieved_indices.append(index)
                except ValueError:
                    continue
            
            return achieved_indices
            
        except Exception as e:
            print(f"ëª©í‘œ ë‹¬ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []
